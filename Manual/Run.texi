@node Run Parameters
@section Run Parameters

The following parameters describe general run information. They may be set in the @code{(run)} section of the run-card, see @ref{Input structure}.

@menu
* EVENTS::            Number of events to generate.
* OUTPUT::            Output level.
* LOG_FILE::          Log file.
* RANDOM_SEED::       Seed for random number generator.
* ANALYSIS::          Switch internal analysis on or off.
* ANALYSIS_OUTPUT::   Directory for generated analysis histogram files.
* TIMEOUT::           Run time limitation.
* BATCH_MODE::        Batch mode settings.
* SPIN_CORRELATIONS:: Switch spin correlations on/off.
* NUM_ACCURACY::      Accuracy for gauge tests.

* SHERPA_CPP_PATH::   The C++ code generation path.
* SHERPA_LIB_PATH::   The runtime library path.

* Event output formats:: Event output in different formats.
* MPI parallelization::  MPI parallelization with Sherpa.
* Multi-threading::      Multi-threaded integration with Sherpa.
@end menu


@node EVENTS
@subsection EVENTS
@cindex EVENTS
This parameter specifies the number of events to be generated.
@*
It can alternatively be set on the command line through option
@option{-e}, see @ref{Command line}.

@node OUTPUT
@subsection OUTPUT
@cindex OUTPUT
@cindex EVT_OUTPUT
This parameter specifies the output level (verbosity) of the program.
@*
It can alternatively be set on the command line through option
@option{-O}, see @ref{Command line}. A different output level can be 
specified for the event generation step through @option{EVT_OUTPUT}
or command line option @option{-o}, see @ref{Command line}

The value can be any sum of the following:
@itemize @bullet
@item
0: Error messages (-> always displayed).
@item
1: Event display.
@item
2: Informational messages during the run.
@item
4: Tracking messages (lots of output).
@item
8: Debugging messages (even more output).
@end itemize

E.g. OUTPUT=3 would display information, events and errors.

@node LOG_FILE
@subsection LOG_FILE
@cindex LOG_FILE
This parameter specifies the log file. If set, the standard output 
from Sherpa is written to the specified file, but output from child
processes is not redirected. This option is particularly useful to produce
clean log files when running the code in MPI mode, see @ref{MPI parallelization}.
A file name can alternatively be specified on the command line through option
@option{-l}, see @ref{Command line}.

@node RANDOM_SEED
@subsection RANDOM_SEED
@cindex RANDOM_SEED
@cindex RANDOM_SEED1
@cindex RANDOM_SEED2
SHERPA uses a random-number generator as described in
[Florida State University Report FSU-SCRI-87-50].
The two independent integer-valued seeds are specified by the option
``RANDOM_SEED=A B''. The seeds A and B may range from 0 to 31328 and from
0 to 30081, respectively. They can also directly be set using 
``RANDOM_SEED1=A'' and ``RANDOM_SEED2=B'' If RANDOM_SEED is not 
specified at all or only by one integer number, the old random-number 
generator (SHERPA 1.0.6 and older) will be used. This value can also be set 
using the command line option @option{-R}, see @ref{Command line}.

@node ANALYSIS
@subsection ANALYSIS
@cindex ANALYSIS
Analysis routines can be switched on or off by setting the ANALYSIS flag.
The default is no analysis, corresponding to option @option{0}.
This parameter can also be specified on the command line using option
@option{-a}, see @ref{Command line}.

The following analysis handlers are currently available
@table @option
@item Internal
Sherpa's internal analysis handler.
@*
To use this option, the package must be configured with option @option{--enable-analysis}.
@*
An output directory can be specified using @ref{ANALYSIS_OUTPUT}.
@item Rivet
The Rivet package, see @uref{http://projects.hepforge.org/rivet/,,Rivet Website}.
@*
To enable it, Rivet and HepMC have to be installed and Sherpa must be configured
as described in @ref{Rivet analyses}.
@end table

Multiple options can be combined using a comma, e.g. @samp{ANALYSIS=Internal,Rivet}.

@node ANALYSIS_OUTPUT
@subsection ANALYSIS_OUTPUT
@cindex ANALYSIS_OUTPUT
Name of the directory for histogram files when using the internal analysis
and name of the Aida file when using Rivet, see @ref{ANALYSIS}. 
The directory / file will be created w.r.t. the working directory. The default
value is @option{Analysis/}. This parameter can also be specified on the 
command line using option @option{-A}, see @ref{Command line}.

@node TIMEOUT
@subsection TIMEOUT
@cindex TIMEOUT
A run time limitation can be given in user CPU seconds through TIMEOUT. This option is of
some relevance when running SHERPA on a batch system. Since in many cases jobs are just
terminated, this allows to interrupt a run, to store all relevant information and to restart
it without any loss. This is particularly useful when carrying out long integrations.
Alternatively, setting the TIMEOUT variable to -1, which is the default setting, translates into
having no run time limitation at all. The unit is seconds.

@node BATCH_MODE
@subsection BATCH_MODE
@cindex BATCH_MODE
Whether or not to run Sherpa in batch mode. The default is @option{1}, meaning Sherpa
does not attempt to save runtime information when catching a signal or an exception.
On the contrary, if option @option{0} is used, Sherpa will store potential integration
information and analysis results, once the run is terminated abnormally.

@emph{Note that when running the code on a cluster or in a grid environment, BATCH_MODE
should never be different from 1.}

The command line option @option{-b} should therefore not be used in this case, see
@ref{Command line}.

@node SPIN_CORRELATIONS
@subsection SPIN_CORRELATIONS
@cindex SPIN_CORRELATIONS
The algorithm used to transfer spin-correlation information from AMEGIC++ to HADRONS++
is switched off (=0) by default. It can be switched on via SPIN CORRELATIONS=1. Process
libraries have to be re-created in this case.

@node NUM_ACCURACY
@subsection NUM_ACCURACY
@cindex NUM_ACCURACY
The targeted numerical accuracy can be specified through NUM ACCURACY, e.g. for comparing
two numbers. This might have to be reduced if gauge tests fail for numerical reasons.

@node SHERPA_CPP_PATH
@subsection SHERPA_CPP_PATH
@cindex SHERPA_CPP_PATH
The path in which Sherpa will eventually store dynamically created C++ source code.
If not specified otherwise, sets @option{SHERPA_LIB_PATH} to 
@samp{$SHERPA_CPP_PATH/Process/lib}. This value can also be set using the command line 
option @option{-L}, see @ref{Command line}.

@node SHERPA_LIB_PATH
@subsection SHERPA_LIB_PATH
@cindex SHERPA_LIB_PATH
The path in which Sherpa looks for dynamically linked libraries from previously created
C++ source code, cf. @ref{SHERPA_CPP_PATH}.


@node Event output formats
@subsection Event output formats
@cindex SHERPA_OUTPUT
@cindex HEPMC2_GENEVENT_OUTPUT
@cindex HEPEVT_OUTPUT
@cindex LHEF_OUTPUT
@cindex ROOTNTUPLE_OUTPUT
@cindex FILE_SIZE
@cindex EVT_FILE_PATH
@cindex OUTPUT_PRECISION
@cindex EVENT_MODE

Sherpa provides the possibility to output events in its native and two other
output formats:
The HepEVT common block structure or the HepMC format.
The authors of Sherpa assume
that the user is sufficiently acquainted with these formats when
selecting them.

If the events are to be written to file, the following parameters have to be
specified:

@table @option
@item SHERPA_OUTPUT=<filename>
Filename for output in Sherpa format
@item HEPMC2_GENEVENT_OUTPUT=<filename>
Filename for output in HepMC::IO_GenEvent format.
@item HEPMC2_SHORT_OUTPUT=<filename>
Filename for output in HepMC::IO_GenEvent format. Only incoming beams and 
outgoing particles are stored. Intermediate and decayed particles are not 
listed.
@item HEPEVT_OUTPUT=<filename>
Filename for output in HepEvt format.
@item LHEF_OUTPUT=<filename>
Filename for output in Les Houches Event File format. This output format is 
intended for output of matrix element configurations only. Since the 
format requires PDF information to be written out in the outdated 
PDFLIB/LHAGLUE enumeration format this is only available automatically if 
LHAPDF is used, otherwise the indetification numbers have to be given 
explicitly via @code{LHEF_PDF_NUMBER} (@code{LHEF_PDF_NUMBER_1} and 
@code{LHEF_PDF_NUMBER_2} if both beams carry different structure functions).
@item ROOTNTUPLE_OUTPUT=<filename>
Filename for output in ROOT ntuple format for NLO event generation. 
For details on ntuple format, see @ref{Structure of ROOT NTuple Output}.
This output option is only available if Sherpa was linked to ROOT during 
installation by using the configure option @code{--enable-root=/path/to/root}.
@end table

With these keywords the filename's root can be
specified, i.e. @code{HEPEVT_OUTPUT=<filename>} will create files named
@code{<filename>.#.hepevt}, where the hash mark numerates the files if events are
split into multiple files.
The output can be further steered with the following options:

@table @option
@item FILE_SIZE
Number of events per file (default: 1000).
@item EVT_FILE_PATH
Directory where the files will be stored.
@item OUTPUT_PRECISION
Steers the precision of all numbers written to file.
@end table

To write events directly to gzipped files instead of plain text, the
option @option{--enable-gzip} has to be specified during the installation.

There is also the option to change the format of the event output printed to
screen (if any) with the switch @code{EVENT_MODE}:

@table @option
@item EVENT_MODE=Sherpa
Blob list output (default)
@item EVENT_MODE=HepMC
GenEvent print method
@item EVENT_MODE=HepMC_Short
GenEvent print method of shortend event record
@item EVENT_MODE=HepEvt
HepEvt common block
@end table

@node MPI parallelization
@subsection MPI parallelization
@cindex PSI_ADJUST_POINTS
MPI parallelization in Sherpa can be enabled using the configuration
option @samp{--enable-mpi}. Sherpa supports
@uref{http://www.open-mpi.org/,,OpenMPI}
and
@uref{http://www.mcs.anl.gov/research/projects/mpich2/,,MPICH2}
. For detailed instructions on how to run a parallel program, please refer
to the documentation of your local cluster resources or the many excellent 
introductions on the internet. MPI parallelization is mainly intended to speed up
the integration process, as event generation can be parallelized trivially 
by starting multiple instances of Sherpa with different random seed, cf.
@ref{RANDOM_SEED}. However, both the internal analysis module and the Root
NTuple writeout can be used with MPI. Note that these require substantial 
data transfer. We only recommend to use them in MPI mode if your local cluster
has sufficient ethernet bandwidth.

When compiled with MPI support, Sherpa implements an automatic load balancing 
to make optimal use of potentially different types of cluster nodes. 
If you do not wish Sherpa to take control, this option can be disabled 
by setting @option{PSI_ADJUST_POINTS=0}.

@node Multi-threading
@subsection Multi-threading
@cindex PG_THREADS
@cindex COMIX_ME_THREADS
@cindex COMIX_PS_THREADS

Multi-threaded integration in Sherpa can be enabled using the configuration
option @samp{--enable-multithread}. Subsequently the computation of amplitudes
for large groups of processes is split into a number of threads which is limited 
from above by the parameter @option{PG_THREADS}. This parameter can also
be specified using the command line option @option{-j}, see @ref{Command line}.
Additionally, matrix-element calculation and phase-space evaluation for a 
single process with Comix can be distributed to different threads according to 
@mycite{Gleisberg2008fv}. The number of threads is then specified using the 
parameters @option{COMIX_ME_THREADS} and @option{COMIX_PS_THREADS}, respectively.
